{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DC-sW0RSf9R",
        "outputId": "9a8c9746-228e-4ecd-b950-1e183c48d753"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Model and scaler saved successfully!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import joblib\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/NEWCaseStudyData1.csv\")\n",
        "\n",
        "# Convert time to timestamp (in seconds)\n",
        "df['BaseDateTime'] = pd.to_datetime(df['BaseDateTime'], errors='coerce')\n",
        "df.dropna(subset=['BaseDateTime', 'LAT', 'LON'], inplace=True)\n",
        "df['Timestamp'] = df['BaseDateTime'].astype('int64') // 10**9\n",
        "\n",
        "# Select features\n",
        "features = df[['LAT', 'LON', 'Timestamp']]\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(features)\n",
        "\n",
        "# Train Isolation Forest\n",
        "model = IsolationForest(n_estimators=100, contamination=0.05, random_state=42)\n",
        "model.fit(X_scaled)\n",
        "\n",
        "# Save model and scaler\n",
        "joblib.dump(model, 'model.pkl')\n",
        "joblib.dump(scaler, 'scaler.pkl')\n",
        "\n",
        "print(\" Model and scaler saved successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import joblib\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# === Step 1: Load trained model and scaler ===\n",
        "model = joblib.load('model.pkl')\n",
        "scaler = joblib.load('scaler.pkl')\n",
        "\n",
        "# === Step 2: Load new ship data ===\n",
        "df = pd.read_csv(\"/content/NEWCaseStudyData1.csv\")  # Update path if needed\n",
        "\n",
        "# === Step 3: Preprocess the data ===\n",
        "# Convert BaseDateTime to proper datetime format\n",
        "df['BaseDateTime'] = pd.to_datetime(df['BaseDateTime'], errors='coerce')\n",
        "\n",
        "# Drop rows with missing critical data\n",
        "df.dropna(subset=['BaseDateTime', 'LAT', 'LON'], inplace=True)\n",
        "\n",
        "# Create a Unix timestamp column\n",
        "df['Timestamp'] = df['BaseDateTime'].astype('int64') // 10**9\n",
        "\n",
        "# Extract features used during training\n",
        "features = df[['LAT', 'LON', 'Timestamp']]\n",
        "\n",
        "# Scale features using the same scaler\n",
        "X_scaled = scaler.transform(features)\n",
        "\n",
        "# === Step 4: Use the trained model to predict anomalies ===\n",
        "predictions = model.predict(X_scaled)  # Output: 1 (normal) or -1 (anomaly)\n",
        "df['Anomaly'] = predictions\n",
        "\n",
        "# === Step 5: Extract and display anomalies ===\n",
        "anomalies = df[df['Anomaly'] == -1]\n",
        "\n",
        "# Display the anomaly points\n",
        "print(\"\\nAnomalies Detected:\")\n",
        "print(anomalies[['VesselName', 'BaseDateTime', 'LAT', 'LON']])\n",
        "\n",
        "# === Step 6: Optional – Save anomalies to a new CSV ===\n",
        "anomalies.to_csv(\"anomalies_detected.csv\", index=False)\n",
        "print(\"\\nAnomalies saved to 'anomalies_detected.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd1fWdSdZpmj",
        "outputId": "456be61b-b532-47a8-a927-98284363f6f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Anomalies Detected:\n",
            "   VesselName              BaseDateTime    LAT   LON\n",
            "0  VICTORIA L 2025-04-09 07:55:00+00:00  53.46  4.61\n",
            "1  VICTORIA L 2025-04-09 08:05:00+00:00  53.43  4.58\n",
            "\n",
            "Anomalies saved to 'anomalies_detected.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import joblib\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "# === Load and combine datasets ===\n",
        "df1 = pd.read_csv(\"/content/SyntheticShipData.csv\")\n",
        "df2 = pd.read_csv(\"/content/NEWCaseStudyData1.csv\")\n",
        "df = pd.concat([df1, df2], ignore_index=True)\n",
        "\n",
        "# === Preprocess ===\n",
        "df['BaseDateTime'] = pd.to_datetime(df['BaseDateTime'], errors='coerce')\n",
        "df.dropna(subset=['BaseDateTime', 'LAT', 'LON'], inplace=True)\n",
        "df['Timestamp'] = df['BaseDateTime'].astype('int64') // 10**9\n",
        "\n",
        "# === Extract features ===\n",
        "features = df[['LAT', 'LON', 'Timestamp']]\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(features)\n",
        "\n",
        "# === Train Isolation Forest on combined data ===\n",
        "model = IsolationForest(n_estimators=100, contamination=0.05, random_state=42)\n",
        "model.fit(X_scaled)\n",
        "\n",
        "# === Save model and scaler ===\n",
        "joblib.dump(model, 'model_combined.pkl')\n",
        "joblib.dump(scaler, 'scaler_combined.pkl')\n",
        "\n",
        "# === Predict anomalies ===\n",
        "predictions = model.predict(X_scaled)\n",
        "df['Anomaly'] = predictions\n",
        "\n",
        "# === Show stats ===\n",
        "print(\"\\nAnomaly label counts:\")\n",
        "print(df['Anomaly'].value_counts())\n",
        "\n",
        "print(\"\\n Top 10 anomaly points:\")\n",
        "print(df[df['Anomaly'] == -1][['VesselName', 'BaseDateTime', 'LAT', 'LON']])\n",
        "\n",
        "print(\"\\nVessel-wise anomaly count:\")\n",
        "print(df[df['Anomaly'] == -1]['VesselName'].value_counts())\n",
        "\n",
        "# === Save anomalies to CSV ===\n",
        "anomalies = df[df['Anomaly'] == -1]\n",
        "anomalies.to_csv(\"all_anomalies.csv\", index=False)\n",
        "print(\"\\nSaved all detected anomalies to 'all_anomalies.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgEud_YHf72W",
        "outputId": "dd5c6ef9-04e5-4653-e372-51f478c5dc00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Anomaly label counts:\n",
            "Anomaly\n",
            " 1    173\n",
            "-1     10\n",
            "Name: count, dtype: int64\n",
            "\n",
            " Top 10 anomaly points:\n",
            "     VesselName              BaseDateTime        LAT        LON\n",
            "0     SKATZOURA 2025-04-12 07:49:00+00:00   8.350594  76.473676\n",
            "12    SKATZOURA 2025-04-12 08:14:18+00:00   8.395055  76.408694\n",
            "13    SKATZOURA 2025-04-12 08:14:55+00:00   8.396153  76.407096\n",
            "149  VICTORIA L 2025-04-09 07:55:00+00:00  53.460000   4.610000\n",
            "150  VICTORIA L 2025-04-09 08:05:00+00:00  53.430000   4.580000\n",
            "151  VICTORIA L 2025-04-09 08:26:00+00:00  53.350000   4.530000\n",
            "152  VICTORIA L 2025-04-09 08:38:00+00:00  53.320000   4.510000\n",
            "157  VICTORIA L 2025-04-09 09:33:00+00:00  53.120000   4.360000\n",
            "181  VICTORIA L 2025-04-09 15:15:00+00:00  52.380000   3.470000\n",
            "182  VICTORIA L 2025-04-09 15:38:00+00:00  52.370000   3.470000\n",
            "\n",
            "Vessel-wise anomaly count:\n",
            "VesselName\n",
            "VICTORIA L    7\n",
            "SKATZOURA     3\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Saved all detected anomalies to 'all_anomalies.csv'\n"
          ]
        }
      ]
    }
  ]
}